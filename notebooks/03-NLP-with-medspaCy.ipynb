{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/abchapman93/Melbourne_COMP90089_NLP/releases/download/fall_2022/melbourne_comp90089_nlp-0.0.0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287976aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from melbourne_comp90089_nlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208d3e3",
   "metadata": {},
   "source": [
    "# NLP with medspaCy\n",
    "This notebook will introduce the Python package `medspaCy`, a toolkit for clinical NLP.\n",
    "\n",
    "# I. Overview\n",
    "Clinical text has several unique challenges that making doing NLP with EHR notes difficult. Some examples are:\n",
    "- **It is very messy**, with semi-structured formatting from EHR\n",
    "- Clinical documents include **many abbreviations**, some of which are ambiguous\n",
    "- There are **specific tasks** needed in clinical NLP, such as **detecting negation or uncertainty** for concepts in the text\n",
    "\n",
    "Because of these unique challenges, we need specialized tools for working with clinical data. One package we can use for this is called `medspaCy`.\n",
    "\n",
    "## medspacy\n",
    "<img alt=\"MedSpaCy logo\" src=\"https://github.com/medspacy/medspacy/raw/master/images/medspacy_logo.png\">\n",
    "\n",
    "\n",
    "[`medspaCy`](https://github.com/medspacy/medspacy) is an open-source package maintained by NLP developers at the University of Utah and the US Department of Veterans Affairs. It's built using the popular [spaCy](https://spacy.io/) library and is specifically designed for working with clinical notes. \n",
    "\n",
    "The goal of medSpaCy is to provide flexible, easy-to-use spaCy components for common clinical NLP tasks, such as:\n",
    "\n",
    "- Concept extraction\n",
    "- Negation detection\n",
    "- Document section splitting\n",
    "\n",
    "Here are a couple of papers that used medspaCy:\n",
    "\n",
    "- [Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python\n",
    "](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8861690/)\n",
    "- [A Natural Language Processing System for National\n",
    "COVID-19 Surveillance in the US Department of Veterans Affairs](https://aclanthology.org/2020.nlpcovid19-acl.10.pdf)\n",
    "- [ReHouSED: A novel measurement of Veteran housing stability using natural language processing](https://www.sciencedirect.com/science/article/pii/S153204642100232X?via%3Dihub)\n",
    "- [Assessing mortality prediction through different representation models based on concepts extracted from clinical notes](https://arxiv.org/pdf/2207.10872.pdf)\n",
    "- [A Study into patient similarity through representation learning from medical\n",
    "records ](https://arxiv.org/pdf/2104.14229.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2b0a5",
   "metadata": {},
   "source": [
    "## Getting started with medspaCy\n",
    "This notebook will walk show how to use medspaCy to process clinical text and introduce some of the spaCy infrastrcuture. We'll then design some rules to extract concepts from clinical texts.\n",
    "\n",
    "\n",
    "To get started with medspaCy, we'll import the library and then load a **model** which we will call `nlp`. A model in spaCy is the object which processes a note and performs the various steps of text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3e1e7",
   "metadata": {},
   "source": [
    "### `nlp`\n",
    "The simplest way to create a model in medspaCy is `medspaCy.load()`. This is a spaCy `English` class. You can also load models for other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca118fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e1eff",
   "metadata": {},
   "source": [
    "### `Doc`\n",
    "To process a text, we call `nlp(text)` and save the result to `doc`. Calling `nlp` on a text returns an object from the `Doc` class. In spaCy, `Doc` objects represent a single text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b42ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Chief complaint: Fever and SOB\"\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600692f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e6e8ff1",
   "metadata": {},
   "source": [
    "### `Token`\n",
    "A `Token` is a single word, symbol, or whitespace in a `doc`. When we create a `doc` object, the text broken up into individual tokens. This is called **\"tokenization\"**.\n",
    "\n",
    "**Discussion**: Look at the tokens generated from this text snippet. What can you say about the tokenization method? Is it as simple as splitting up into words every time we reach a whitespace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ae94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937f317",
   "metadata": {},
   "source": [
    "If we access a single index of a doc, we get a token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = doc[0]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_type_text0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717188d5",
   "metadata": {},
   "source": [
    "### `Span`\n",
    "While a `Token` represents a single word, a `Span` represents one or more words from a `Doc`. We can get a `Span` by slicing a `Doc` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = doc[0:3]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1030c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea63da6",
   "metadata": {},
   "source": [
    "## Pipeline Components\n",
    "Under the hood, the `nlp` object goes through a number of sequential steps to process the text. This is called a **pipeline** and it allows us to create modular, independent processing steps when analyzing text. We can see the names of our pipeline components through the `nlp.pipe_names` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fa566",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a19cdb",
   "metadata": {},
   "source": [
    "There's also a hidden component which runs before all of them called the `tokenizer`. This splits text up into tokens and creates a `Doc` object, which is then passed on to the rest of the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b5fab",
   "metadata": {},
   "source": [
    "We'll learn more about some of these pipeline components in the following notebooks. First, we'll start with the `target_matcher` component and learn how to extract clinical concepts from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8844193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, remove some components we don't need\n",
    "nlp.remove_pipe(\"medspacy_pyrush\")\n",
    "nlp.remove_pipe(\"medspacy_context\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e382ce0",
   "metadata": {},
   "source": [
    "## Concept Extraction\n",
    "One of the first step in many clinical NLP tasks is identiyfing particular **concepts** in text. These will vary in each use case, but some common examples of concepts are:\n",
    "- Diagnoses\n",
    "- Signs and symptoms\n",
    "- Medications\n",
    "- Tests\n",
    "\n",
    "### TODO\n",
    "For each of the texts below, identify the best description of the concepts **in bold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc682c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_medical_concepts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fa2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_medical_concepts_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_medical_concepts_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f83a2",
   "metadata": {},
   "source": [
    "The task of extracting these spans of text is called **named entity recognition (NER)**. This can be done using either machine learning models or rule-based models. In this class, we'll focus on building rule-based systems. In rule-based NLP, we define patterns to match concepts in text. SpaCy offers many [rule-based methods](https://spacy.io/usage/rule-based-matching). MedSpaCy uses a pipeline component called `TargetMatcher` and rules defined by a class called `TargetRule`. Extracted concepts will be stored as `Span` objects in `doc.ents`.\n",
    "\n",
    "### `target_matcher`\n",
    "To start adding rules, we'll first need to access the pipeline component. We can do this by calling `nlp.get_pipe(pipe_name)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c985810",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1907cf6",
   "metadata": {},
   "source": [
    "Next we need to actually write some rules using the `TargetRule` class. Target rules require two positional arguments:\n",
    "- `literal`: A span of text to match in the text (case insensitive)\n",
    "- `category`: The label to assign to extracted concepts\n",
    "\n",
    "(There are also a few keyword arguments that we'll explore later, but these are the two required arguments.)\n",
    "\n",
    "Let's say that we want to extract patient diagnoses from the following text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_text = \"Pt is a 63M w/ h/o metastatic carcinoid tumor, HTN and hyperlipidemia\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40815d7",
   "metadata": {},
   "source": [
    "There are three diagnoses in this text. The first is `\"metastatic carcinoid tumor\"`. Let's write a rule to capture this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medspacy.target_matcher import TargetRule\n",
    "rule = TargetRule(\"metastatic carcinoid tumor\", \"DIAGNOSIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2badd6",
   "metadata": {},
   "source": [
    "We can then add it to our target matcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher.add(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher.rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41bcfc",
   "metadata": {},
   "source": [
    "Now let's process the text above and see if it's extracted by our NLP model by looking at `doc.ents`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e41d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(dx_text)\n",
    "doc.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f906a5a",
   "metadata": {},
   "source": [
    "The `target_matcher` added a `Span` to the doc's entities representing the concept we just extracted. Let's assign this span to the variable `ent`. We can see the concept category by checking the `ent.label_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = doc.ents[0]\n",
    "print(ent)\n",
    "print(type(ent))\n",
    "print(ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6faddd",
   "metadata": {},
   "source": [
    "`medspaCy` provides some visualization functions which make it easier to look at what has been extracted from the notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2290023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medspacy.visualization import visualize_ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f39f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ada6e8a",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Edit the cell below to write a list of rules for extracting the two remaining diagnoses from `dx_text`. Then add them to the target matcher and reprocess the doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    TargetRule(\"HTN\", ____),\n",
    "    TargetRule(____, ____),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88831673",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher.____(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53197b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dx = nlp(dx_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc68a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c005cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dx.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d01752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST VALUE\n",
    "test_dx_text.test(doc_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17388c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28626c30",
   "metadata": {},
   "source": [
    "### Advanced pattern matching\n",
    "We could pass in simple strings to our `ruler` to extract exact matches. However, there may be lots of small variations in the text we want to extract, and it will grow cumbersome to type out every single possible string. Instead, we'll do some more advanced matching by using **token attribute matching**.\n",
    "\n",
    "SpaCy allows us to write patterns based on not only the exact text, but other linguistic attributes such as **part-of-speech tag**, **numerical properties**, **regular expressions**, and much more. \n",
    "\n",
    "### Example: Chronic Kidney Disease\n",
    "Each of the texts below mention a different stage of Chronic Kidney Disease:\n",
    "\n",
    "---\n",
    "- 76 year old man with CKD Stage 3.\n",
    "- relevant diagnoses: ckd stage 4\n",
    "- The patient has progressed to ckd stage 5\n",
    "---\n",
    "\n",
    "We could write different target rules to match each text, but sometimes there are too many combinations to feasibly write out every option. Instead of trying to think of the near-infinite number of variations, let's write one pattern which will match all of these clinical problems.\n",
    "\n",
    "An advanced pattern in spaCy is a Python **list**. Each element in that list is a **dictionary** representing each of the **tokens** (individual words) in a span of text. The **keys** of the dictionary represent the token attributes to look at and the **values** represent the values which should trigger a match:\n",
    "\n",
    "---\n",
    "```python\n",
    "[\n",
    "    {\"ATTRIBUTE\": value}, # First token\n",
    "    {\"ATTRIBUTE\": value}, # Second token\n",
    "    {\"ATTRIBUTE\": value} # Third token\n",
    "]\n",
    "```\n",
    "\n",
    "Let's now write a pattern which will match both **\"CKD Stage 3\"** and **\"ckd stage two\"**. What attributes are similar between these two spans of text? What is a general pattern that you could match?\n",
    "\n",
    "Both spans of text start out with the text **\"CKD\"**, although one is upper-case and one is lower-case. To match either, we will match on the **\"LOWER\"** attribute of the token (which is the lower-case text):\n",
    "\n",
    "```python\n",
    "{\"LOWER\": \"ckd\"}\n",
    "```\n",
    "\n",
    "The second token is **\"Stage\"**, but again there's a difference in case. So let's use the **\"LOWER\"** attribute again:\n",
    "\n",
    "```python\n",
    "{\"LOWER\": \"stage\"}\n",
    "```\n",
    "\n",
    "Finally, the last token is a number. In this text there are **\"3\"** and **\"two\"**, but there could potentially be any number **1-5**. So let's just match any number. SpaCy can also recognize that the word **\"two\"** is a number by using the **\"LIKE_NUM\"** attribute, which is a boolean:\n",
    "\n",
    "```python\n",
    "{\"LIKE_NUM\": True}\n",
    "```\n",
    "\n",
    "When we put it all together, here is our pattern:\n",
    "```python\n",
    "pattern = [\n",
    "    {\"LOWER\": \"ckd\"}, # Token 1\n",
    "    {\"LOWER\": \"stage\"}, # Token 2\n",
    "    {\"LIKE_NUM\": True} # Token 3\n",
    "]\n",
    "```\n",
    "\n",
    "Once we've written a rule like this, we can add it to the target rule using the `pattern` keyword argument.\n",
    "\n",
    "```python\n",
    "TargetRule(\"CKD Stage X\", \"DIAGNOSIS\", pattern=pattern)\n",
    "```\n",
    "\n",
    "Another helpful attribute for advanced pattern matching is `\"OP\"`, which lets the pattern be flexible on how many times the token is matched:\n",
    "\n",
    "- `\"OP\": \"?` matches zero or 1 time\n",
    "- `\"OP\": \"*` matches zero or more times (up to any number)\n",
    "- `\"OP\": \"+` matches 1 or more time\n",
    "\n",
    "So if we modified the pattern above to include an operator attribute then we could make `\"stage\"` and the number optional and match just \"`ckd`\":\n",
    "\n",
    "```python\n",
    "pattern = [\n",
    "    {\"LOWER\": \"ckd\"}, # Token 1\n",
    "    {\"LOWER\": \"stage\", \"OP\": \"?\"}, # Token 2\n",
    "    {\"LIKE_NUM\": True, \"OP\": \"?\"} # Token 3\n",
    "]\n",
    "```\n",
    "\n",
    "#### TODO\n",
    "Finish the code below to create a rule matching which will match all three examples of CKD. Then add it to the pipeline and test your model. You can test it on the three examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"76 year old man with CKD Stage 3.\",\n",
    "    \"relevant diagnoses: ckd stage 4\",\n",
    "    \"The patient has progressed to ckd stage 5\",\n",
    "    \"She was dx'd with CKD in January.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = TargetRule(\"CKD Stage X\", \"DIAGNOSIS\", \n",
    "                  ____=____\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_matcher.add(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74583ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    visualize_ent(nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TEST VALUE\n",
    "test_ckd_stage_x.test(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d3fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4729b4e6",
   "metadata": {},
   "source": [
    "## Concept extraction practice\n",
    "Let's return to the example discharge summary we looked at in a previous notebook. Add rules to `target_matcher` that will extract the following concepts from the text:\n",
    "- `\"DIAGNOSIS\"`\n",
    "- `\"MEDICATION\"`\n",
    "- `\"SIGN/SYMPTOM\"`\n",
    "- `\"SOCIAL_DETERMINANT\"`\n",
    "- `\"PROCEDURE\"`\n",
    "\n",
    "It might be useful to work in teams with clinicians or people familiar with these concepts so you can identify and define them. You don't need to extract every concept from the text (there are a lot!) so maybe just go through the note and add a few examples of each conceptt. If you'd like to write more sophisticated rules, it may be helpful to review spaCy's [rule-based NLP documentation](https://spacy.io/usage/rule-based-matching#matcher) (look at the documentation under `Matcher`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CELL TO SEE HINT\n",
    "hint_discharge_summ_target_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a fresh NLP model\n",
    "nlp = medspacy.load(enable=[\"medspacy_target_matcher\"])\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "target_matcher.add(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(disch_summ)\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b3b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
